{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed5b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081731d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "\n",
    "# ============ 1) coarse-label version CIFAR-100 ============\n",
    "class CIFAR100Coarse(CIFAR100):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.coarse_targets = self._fine_to_coarse(self.targets)\n",
    "\n",
    "    def _fine_to_coarse(self, targets):\n",
    "        fine_to_coarse = [\n",
    "            4, 1, 14, 8, 0, 6, 7, 7, 18, 3, 3, 14, 9, 18, 7, 11, 3, 9, 7, 11,\n",
    "            6, 11, 5, 10, 7, 6, 13, 15, 3, 15, 0, 11, 1, 10, 12, 14, 16, 9, 11, 5,\n",
    "            5, 19, 8, 8, 15, 13, 14, 17, 18, 10, 16, 4, 17, 4, 2, 0, 17, 4, 18, 17,\n",
    "            10, 3, 2, 12, 12, 16, 12, 1, 9, 19, 2, 10, 0, 1, 16, 12, 9, 13, 15, 13,\n",
    "            16, 19, 2, 4, 6, 19, 5, 5, 8, 19, 18, 1, 2, 15, 6, 13, 8, 8, 15, 6\n",
    "        ]\n",
    "        return [fine_to_coarse[i] for i in targets]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, _ = super().__getitem__(index)\n",
    "        target = self.coarse_targets[index]\n",
    "        return img, target\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "torch.manual_seed(100)\n",
    "\n",
    "# 1) define train / eval  transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
    "                         (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4865, 0.4409),\n",
    "                         (0.2673, 0.2564, 0.2762)),\n",
    "])\n",
    "\n",
    "# \n",
    "full_len = 50000\n",
    "indices = torch.randperm(full_len)\n",
    "train_indices = indices[:50000]\n",
    "val_indices   = indices[40000:]\n",
    "\n",
    "# 3)  coarse-label replace fine-label\n",
    "train_full = CIFAR100Coarse(root='./data', train=True, download=True, transform=train_transform)\n",
    "val_full   = CIFAR100Coarse(root='./data', train=True, download=True, transform=eval_transform)\n",
    "test_dataset  = CIFAR100Coarse(root='./data', train=False, download=True, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_full, train_indices)\n",
    "val_dataset   = Subset(val_full,   val_indices)\n",
    "\n",
    "# 4) DataLoader \n",
    "use_cuda = torch.cuda.is_available()\n",
    "common_kwargs = dict(num_workers=8, pin_memory=use_cuda)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True,  **common_kwargs)\n",
    "val_loader   = DataLoader(test_dataset,   batch_size=1000, shuffle=False, **common_kwargs)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=10000, shuffle=False, **common_kwargs)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18_CIFAR(nn.Module):\n",
    "    def __init__(self, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(weights=None)\n",
    "        self.model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.model.maxpool = nn.Identity()\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621463d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoupledModel(nn.Module):\n",
    "    def __init__(self, width=32, num_classes=100, kb=1.0, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.C  = num_classes\n",
    "        self.kb = kb\n",
    "        self.device_E = torch.device(\"cuda:5\")\n",
    "        self.device_S = torch.device(\"cuda:5\")\n",
    "\n",
    "        # \n",
    "        self.E_net = ResNet18_CIFAR(num_classes=num_classes).to(self.device_E)\n",
    "        self.S_net = ResNet18_CIFAR(num_classes=num_classes).to(self.device_S)\n",
    "\n",
    "    def forward_image(self, x_img):\n",
    "        \"\"\"\n",
    "       \n",
    "        \"\"\"\n",
    "        x_E = x_img.to(self.device_E, non_blocking=True)\n",
    "\n",
    "        with torch.cuda.device(self.device_E):\n",
    "            E_mat = self.E_net(x_E)\n",
    "\n",
    "        # \n",
    "        x_S = x_img.to(self.device_S, non_blocking=True)\n",
    "        with torch.cuda.device(self.device_S):\n",
    "            S_mat = self.S_net(x_S)\n",
    "\n",
    "        # \n",
    "        E_mat = E_mat.to(self.device_E, non_blocking=True).float()\n",
    "        S_mat = S_mat.to(self.device_E, non_blocking=True).float()\n",
    "\n",
    "        sub_outs = torch.stack([E_mat, S_mat], dim=1)\n",
    "        return E_mat, S_mat, sub_outs\n",
    "    def _normalize_T(self, T, B, device):\n",
    "        \"\"\"\n",
    "       \n",
    "        \"\"\"\n",
    "        if not torch.is_tensor(T):\n",
    "            T = torch.tensor(T, dtype=torch.float32, device=device)\n",
    "\n",
    "        T = T.to(device)\n",
    "        if T.dim() == 0:             # number -> [1,1,1]\n",
    "            T = T.view(1, 1, 1)\n",
    "        elif T.dim() == 1:           # [M] -> [1,M,1]\n",
    "            T = T.view(1, -1, 1)\n",
    "        elif T.dim() == 2:\n",
    "            if T.size(1) == 1:       # [B,1] 或 [M,1]\n",
    "                if T.size(0) == B:   # [B,1] -> [B,1,1]\n",
    "                    T = T.view(B, 1, 1)\n",
    "                else:                # [M,1] -> [1,M,1]\n",
    "                    T = T.view(1, -1, 1)\n",
    "            else:                    # [B,M] -> [B,M,1]\n",
    "                T = T.unsqueeze(-1)\n",
    "        # If [B,M,1] return\n",
    "        return T\n",
    "    def forward(self, x_img, T):\n",
    "        \"\"\"\n",
    "      \n",
    "        \"\"\"\n",
    "        device = x_img.device\n",
    "        eps = 1e-9\n",
    "        B = x_img.size(0)\n",
    "\n",
    "        #  E(x), S(x)\n",
    "        E_mat, S_mat, sub_outs = self.forward_image(x_img)  # [B,C], [B,C], [B,2,C]\n",
    "        # S_pos = S_mat ** 2\n",
    "        S_pos = F.softplus(S_mat)\n",
    "\n",
    "        #  T -> [B, M, 1]\n",
    "        T = self._normalize_T(T, B, device)                 # [B,M,1] 或 [1,M,1]\n",
    "        # [B, M, C]\n",
    "        E_b = E_mat.unsqueeze(1)                            # [B,1,C]\n",
    "        S_b = S_pos.unsqueeze(1)                            # [B,1,C]\n",
    "\n",
    "        # [B, M, C]\n",
    "        scores_bmc = - (E_b - T * S_b) / (self.kb * (T + eps)) - (S_b / (100.0 * self.kb))**2\n",
    "        probs_bmc  = F.softmax(scores_bmc, dim=2)           # [B, M, C]\n",
    "\n",
    "        #  [B,C]\n",
    "        if scores_bmc.size(1) == 1:\n",
    "            scores = scores_bmc.squeeze(1)                  # [B,C]\n",
    "            probs  = probs_bmc.squeeze(1)                   # [B,C]\n",
    "        else:\n",
    "            scores = scores_bmc.mean(dim=1)                 # [B,C] \n",
    "            probs  = probs_bmc.mean(dim=1)                  # [B,C]\n",
    "\n",
    "        return probs, scores, sub_outs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26809871",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnableTSet(nn.Module):\n",
    "    def __init__(self, K=3, T_min=0.1, T_max=10.0):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.T_min = T_min\n",
    "        self.T_max = T_max\n",
    "        self.raw_lambdas = nn.Parameter(torch.randn(K))\n",
    "\n",
    "    def forward(self):\n",
    "        lambdas = torch.sigmoid(self.raw_lambdas)  # [0,1]\n",
    "        Ts = self.T_min + (self.T_max - self.T_min) * lambdas  # [K]\n",
    "        return torch.cat([torch.tensor([1.0], device=Ts.device), Ts], dim=0)  # [K+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616490f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer_posterior_T(model, x, y_onehot, T_grid, loss_fn=None):\n",
    "    \"\"\"\n",
    "    q(T|x,y) ∝ exp(-CE(p(y|x,T), y))\n",
    "    x:       [N,3,32,32], y_onehot: [N,10]\n",
    "    T_grid:  [M,1]\n",
    "    return:  qT: [N,M]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    N, M = x.size(0), T_grid.size(0)\n",
    "\n",
    "    # \n",
    "    x_rep = x.unsqueeze(1).repeat(1, M, 1, 1, 1).reshape(N * M, 3, 32, 32)\n",
    "    T_rep = T_grid.view(1, M, 1).expand(N, M, 1).reshape(N * M, 1)\n",
    "    y_rep = y_onehot.unsqueeze(1).repeat(1, M, 1).reshape(N * M, -1)  # [N*M, C]\n",
    "\n",
    "    # \n",
    "    _, scores, _ = model(x_rep, T_rep)             # scores: [N*M, C]\n",
    "    log_probs = F.log_softmax(scores, dim=1)       # [N*M, C]\n",
    "\n",
    "    # \n",
    "    ce_vec = -(y_rep * log_probs).sum(dim=1)       # [N*M]\n",
    "\n",
    "    # \n",
    "    ce_mat = ce_vec.view(N, M)\n",
    "    qT = torch.softmax(-ce_mat, dim=1)             # [N, M]\n",
    "    return qT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler(enabled=True)\n",
    "\n",
    "def em_train_step_optimized_T(model, x, y_onehot, T_module, optimizer, scheduler=None):\n",
    "    \"\"\"\n",
    "    E-step + Worst-T M-step\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    T_grid = T_module()                           # [M]\n",
    "    N, C = y_onehot.shape\n",
    "    M = T_grid.size(0)\n",
    "    device_E = model.device_E\n",
    "\n",
    "    with autocast():\n",
    "        #\n",
    "        E_mat, S_mat, _ = model.forward_image(x)  # [N, C] on device_E\n",
    "        S_pos = F.softplus(S_mat)\n",
    "       \n",
    "        T_norm = model._normalize_T(T_grid, B=N, device=device_E)  # [B,M,1]\n",
    "        E_b = E_mat.unsqueeze(1)                # [N,1,C]\n",
    "        S_b = S_pos.unsqueeze(1)                # [N,1,C]\n",
    "        eps = 1e-9\n",
    "        scores_bmc = - (E_b - T_norm * S_b) / (model.kb * (T_norm + eps)) - (S_b / (100.0 * model.kb)) ** 2\n",
    "        log_probs_bmc = F.log_softmax(scores_bmc, dim=2)     # [N, M, C]\n",
    "\n",
    "        # CE: [N, M]\n",
    "        ce_bm = -(y_onehot.unsqueeze(1) * log_probs_bmc).sum(dim=2)\n",
    "\n",
    "        # E-step: compute posterior q(T|x,y)\n",
    "        qT = torch.softmax(-ce_bm.detach(), dim=1)  # [N, M],\n",
    "\n",
    "        # M-step:\n",
    "       \n",
    "        lambda_sharp = 5.0\n",
    "        qT = torch.softmax(-lambda_sharp * ce_bm, dim=1)\n",
    "        loss = (qT * ce_bm).sum() / N # worst-T\n",
    "        \n",
    "\n",
    "    # backward & step\n",
    "    optimizer.zero_grad()\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    if scheduler: scheduler.step()\n",
    "\n",
    "    #\n",
    "    return loss.item(), qT.detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e051e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_accuracy_posterior_labeled(model, loader, device, T_module):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "\n",
    "    # \n",
    "    T_grid = T_module().detach().to(device)  # [M,1]\n",
    "    M = T_grid.size(0)\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        N, Cimg, H, W = x.shape\n",
    "\n",
    "        #  (x, T)\n",
    "        x_rep = x.unsqueeze(1).repeat(1, M, 1, 1, 1).reshape(N*M, Cimg, H, W)\n",
    "        T_rep = T_grid.view(1, M, 1).expand(N, M, 1).reshape(N*M, 1)\n",
    "\n",
    "        # \n",
    "        probs, scores, *_ = model(x_rep, T_rep)         # [N*M, C]\n",
    "        Ccls = probs.size(1)\n",
    "        probs_nm  = probs.view(N, M, Ccls)              # [N, M, C]\n",
    "        scores_nm = scores.view(N, M, Ccls)             # [N, M, C]\n",
    "\n",
    "        # \n",
    "        log_probs_nm = F.log_softmax(scores_nm, dim=2)  # [N, M, C]\n",
    "        y_onehot = F.one_hot(y, num_classes=Ccls).float()          # [N, C]\n",
    "        ce_mat = -(y_onehot.unsqueeze(1) * log_probs_nm).sum(dim=2)  # [N, M]\n",
    "\n",
    "        # E-step: q(T|x,y)\n",
    "        qT = torch.softmax(-ce_mat, dim=1)              # [N, M]\n",
    "\n",
    "        #  p(y|x)\n",
    "        probs_marg_q = (qT.unsqueeze(-1) * probs_nm).sum(dim=1)  # [N, C]\n",
    "\n",
    "        # \n",
    "        pred = probs_marg_q.argmax(dim=1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total   += N\n",
    "\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753d5d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"TORCH_CUDNN_V8_API_ENABLED\"] = \"1\"\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "width = 32\n",
    "kb = 1.0\n",
    "em_epochs = 201 # \n",
    "lr = 1e-3\n",
    "\n",
    "model = CoupledModel(width=width, num_classes=20, kb=kb, in_channels=3).to(device)\n",
    "T_module = LearnableTSet(K=4, T_min=0.1, T_max=10.0).to(device)                     # \n",
    "# optimizer = torch.optim.Adam(list(model.parameters()) + list(T_module.parameters()), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=501)\n",
    "params = [\n",
    "    {\"params\": model.E_net.parameters(), \"lr\": 0.01,\"weight_decay\": 5e-4},\n",
    "    {\"params\": model.S_net.parameters(), \"lr\": 0.4,\"weight_decay\": 5e-4},\n",
    "    {\"params\": T_module.parameters(), \"lr\": 0.001, \"weight_decay\": 0.0},  # 避免对 T_module 做 L2 正则\n",
    "]\n",
    "optimizer = torch.optim.SGD(params,momentum=0.9)\n",
    "                           \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "T_records = []  # \n",
    "for epoch in range(em_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for b, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(device)                                   # [N, 3, 32, 32]\n",
    "        y_onehot = F.one_hot(y, num_classes=100).float().to(device)  # [N,10]\n",
    "\n",
    "        # EM + AMP  + Learnable T\n",
    "        loss, qT = em_train_step_optimized_T(model, x, y_onehot, T_module, optimizer, scheduler)\n",
    "        total_loss += loss\n",
    "\n",
    "    # \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # \n",
    "    with torch.no_grad():\n",
    "        T_eval_grid = T_module()\n",
    "        val_acc = evaluate_accuracy_posterior_labeled(model, val_loader, device, T_module)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        current_T = T_eval_grid.detach().cpu().numpy().flatten()\n",
    "        T_records.append(current_T.copy())  # \n",
    "\n",
    "    #  \n",
    "    if epoch % 10 == 0 or epoch == em_epochs - 1:\n",
    "        print(f\"Epoch {epoch}: Loss = {avg_loss:.6f}, Val Acc = {val_acc:.6f}, T = {current_T}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a961abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def posterior_T_labeled(model, x, y, T_module, device):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    # \n",
    "    T_grid = T_module()                  # [M,1]\n",
    "    T_grid = T_grid.to(device)\n",
    "    M = T_grid.size(0)\n",
    "\n",
    "    N, Cimg, H, W = x.shape\n",
    "\n",
    "    #  (x, T)\n",
    "    x_rep = x.unsqueeze(1).repeat(1, M, 1, 1, 1).reshape(N*M, Cimg, H, W)\n",
    "    T_rep = T_grid.view(1, M, 1).expand(N, M, 1).reshape(N*M, 1)\n",
    "    y_rep = y.unsqueeze(1).repeat(1, M).reshape(N*M).long()  # [N*M]\n",
    "\n",
    "    # \n",
    "    probs, scores, *_ = model(x_rep, T_rep)   # [N*M, C]\n",
    "    log_probs = F.log_softmax(scores, dim=1)\n",
    "\n",
    "    # CE loss: -log p(y_i | x_i, T_m)\n",
    "    ce_vec = F.nll_loss(log_probs, y_rep, reduction=\"none\")  # [N*M]\n",
    "    ce_mat = ce_vec.view(N, M)                               # [N, M]\n",
    "\n",
    "    #  q(T|x,y) ∝ exp(-CE)\n",
    "    qT = torch.softmax(-ce_mat, dim=1)                       # [N, M]\n",
    "\n",
    "    # MAP\n",
    "    idx_map = qT.argmax(dim=1)                               # [N]\n",
    "    T_map = T_grid.view(-1)[idx_map]                       # [N]\n",
    "\n",
    "    return qT, T_map, idx_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f72b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def posterior_T_labeled_all(model, loader, T_module, device):\n",
    "    model.eval()\n",
    "    all_qT = []\n",
    "    all_Tmap = []\n",
    "    all_idx = []\n",
    "\n",
    "    for x, y in loader:  # \n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        qT, T_map, idx_map = posterior_T_labeled(model, x, y, T_module, device)\n",
    "        all_qT.append(qT.cpu())\n",
    "        all_Tmap.append(T_map.cpu())\n",
    "        all_idx.append(idx_map.cpu())\n",
    "\n",
    "    return torch.cat(all_qT), torch.cat(all_Tmap), torch.cat(all_idx)\n",
    "\n",
    "\n",
    "device = next(model.parameters()).device  # 或 torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#  [N_val, M]\n",
    "qT_all, Tmap_all, idx_all = posterior_T_labeled_all(model, test_loader, T_module, device)\n",
    "\n",
    "print(\"qT_all shape:\", qT_all.shape)  # [N_val, M]\n",
    "print(\"Tmap_all shape:\", Tmap_all.shape)  # [N_val]\n",
    "print(qT_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0083c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "max_idx = torch.argmax(qT_all, dim=1)  # [N]\n",
    "\n",
    "#  one-hot\n",
    "qT_onehot = F.one_hot(max_idx, num_classes=qT_all.shape[1]).float()\n",
    "\n",
    "print(qT_onehot)\n",
    "# qT_onehot: [N, M]\n",
    "counts = qT_onehot.sum(dim=0)              # [M] \n",
    "freqs = counts / qT_onehot.shape[0]        # \n",
    "\n",
    "print(\"Sample of each temperature:\", counts)\n",
    "print(\"Frequnency of each temperature:\", freqs)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "test_acc = evaluate_accuracy_posterior_labeled(model, test_loader, device, T_module)\n",
    "print(f\"Test Accuracy: {test_acc:.6f}\")\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# \n",
    "train_losses = np.array(train_losses)\n",
    "val_accuracies = np.array(val_accuracies)\n",
    "freqs = np.array(freqs)\n",
    "qT_all = np.array(qT_all)\n",
    "# \n",
    "np.savetxt(\"CZnew_LT_train_losses.txt\", train_losses, fmt=\"%.10f\")\n",
    "\n",
    "# \n",
    "np.savetxt(\"CZnew_LT_val_accuracies.txt\", val_accuracies, fmt=\"%.10f\")\n",
    "\n",
    "#\n",
    "np.savetxt(\"CZnew_LT_T.txt\", T_records, fmt=\"%.10f\")\n",
    "\n",
    "# \n",
    "np.savetxt(\"CZnew_LT_freqs.txt\", freqs, fmt=\"%.10f\")\n",
    "\n",
    "# \n",
    "np.savetxt(\"CZnew_LT_qT.txt\", qT_all, fmt=\"%.4f\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
